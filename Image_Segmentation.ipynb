{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5235f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be77c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_segmentation.models.unet import vgg_unet\n",
    "from keras_segmentation.models.fcn import fcn_8\n",
    "from keras_segmentation.models.segnet import mobilenet_segnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ed165",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "948ee8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = vgg_unet(n_classes=51 ,  input_height=416, input_width=608  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d150ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▏                                                                          | 24/367 [00:00<00:01, 239.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 367/367 [00:01<00:00, 235.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Epoch 1/5\n",
      "512/512 [==============================] - 243s 473ms/step - loss: 0.5176 - accuracy: 0.8379\n",
      "Epoch 2/5\n",
      "512/512 [==============================] - 242s 474ms/step - loss: 0.3980 - accuracy: 0.8738\n",
      "Epoch 3/5\n",
      "512/512 [==============================] - 243s 475ms/step - loss: 0.3329 - accuracy: 0.8931\n",
      "Epoch 4/5\n",
      "512/512 [==============================] - 243s 475ms/step - loss: 0.2924 - accuracy: 0.9048\n",
      "Epoch 5/5\n",
      "512/512 [==============================] - 244s 476ms/step - loss: 0.2512 - accuracy: 0.9172\n"
     ]
    }
   ],
   "source": [
    "unet_model.train(\n",
    "    train_images =  \"dataset1/images_prepped_train/\",\n",
    "    train_annotations = \"dataset1/annotations_prepped_train/\",\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "unet_model.save(\"unet_model\",save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ea69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = vgg_unet(n_classes=51 ,  input_height=416, input_width=608  )\n",
    "unet_model.load_weights(\"unet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719c08eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_out = unet_model.predict_segmentation(\n",
    "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "    out_fname=\"vgg_out.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c709c65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:20,  4.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'frequency_weighted_IU': 0.7819252520353657,\n",
       " 'mean_IU': 0.12378392291558143,\n",
       " 'class_wise_IU': array([0.93964203, 0.73341593, 0.07843651, 0.95612464, 0.81399301,\n",
       "        0.73826569, 0.29444917, 0.29180382, 0.58001594, 0.24775371,\n",
       "        0.46835628, 0.17072334, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_model.evaluate_segmentation( inp_images_dir=\"dataset1/images_prepped_test/\"  , annotations_dir=\"dataset1/annotations_prepped_test/\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd64f92",
   "metadata": {},
   "source": [
    "# FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23adf846",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = fcn_8(n_classes=51 ,  input_height=416, input_width=608  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07285295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                           | 22/367 [00:00<00:01, 213.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 367/367 [00:01<00:00, 236.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Epoch 1/5\n",
      "512/512 [==============================] - 288s 552ms/step - loss: 0.7931 - accuracy: 0.7502\n",
      "Epoch 2/5\n",
      "512/512 [==============================] - 282s 551ms/step - loss: 0.5380 - accuracy: 0.8316\n",
      "Epoch 3/5\n",
      "512/512 [==============================] - 282s 550ms/step - loss: 0.4553 - accuracy: 0.8553\n",
      "Epoch 4/5\n",
      "512/512 [==============================] - 285s 557ms/step - loss: 0.4106 - accuracy: 0.8676\n",
      "Epoch 5/5\n",
      "512/512 [==============================] - 284s 554ms/step - loss: 0.3717 - accuracy: 0.8793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "fcn_model.train(\n",
    "    train_images =  \"dataset1/images_prepped_train/\",\n",
    "    train_annotations = \"dataset1/annotations_prepped_train/\",\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "fcn_model.save(\"fcn_model\",save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a4bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = fcn_8(n_classes=51 ,  input_height=416, input_width=608  )\n",
    "fcn_model.load_weights(\"fcn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c80aab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [01:08,  1.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'frequency_weighted_IU': 0.7675438922628892,\n",
       " 'mean_IU': 0.09732702232206446,\n",
       " 'class_wise_IU': array([0.92610972, 0.76163879, 0.00151022, 0.93340039, 0.63461488,\n",
       "        0.89634961, 0.16498122, 0.0793441 , 0.20674588, 0.10412433,\n",
       "        0.05885691, 0.19600208, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcn_model.evaluate_segmentation( inp_images_dir=\"dataset1/images_prepped_test/\"  , annotations_dir=\"dataset1/annotations_prepped_test/\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc310301",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_out = fcn_model.predict_segmentation(\n",
    "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "    out_fname=\"fcn_out.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c94bae",
   "metadata": {},
   "source": [
    "# Segnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58881351",
   "metadata": {},
   "outputs": [],
   "source": [
    "segnet_model = mobilenet_segnet(n_classes=51 ,  input_height=416, input_width=608  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbee1106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                           | 22/367 [00:00<00:01, 211.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 367/367 [00:01<00:00, 236.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Epoch 1/5\n",
      "512/512 [==============================] - 134s 259ms/step - loss: 0.4853 - accuracy: 0.8604\n",
      "Epoch 2/5\n",
      "512/512 [==============================] - 133s 261ms/step - loss: 0.2450 - accuracy: 0.9204\n",
      "Epoch 3/5\n",
      "512/512 [==============================] - 133s 259ms/step - loss: 0.2057 - accuracy: 0.9301\n",
      "Epoch 4/5\n",
      "512/512 [==============================] - 133s 260ms/step - loss: 0.1739 - accuracy: 0.9393\n",
      "Epoch 5/5\n",
      "512/512 [==============================] - 134s 261ms/step - loss: 0.1602 - accuracy: 0.9431\n"
     ]
    }
   ],
   "source": [
    "segnet_model.train(\n",
    "    train_images =  \"dataset1/images_prepped_train/\",\n",
    "    train_annotations = \"dataset1/annotations_prepped_train/\",\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "segnet_model.save(\"segnet_model\",save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1925fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "segnet_model = mobilenet_segnet(n_classes=51 ,  input_height=416, input_width=608  )\n",
    "segnet_model.load_weights(\"segnet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d00135be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:16,  6.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'frequency_weighted_IU': 0.8356919827398727,\n",
       " 'mean_IU': 0.14011907338158,\n",
       " 'class_wise_IU': array([0.90825545, 0.817046  , 0.02799468, 0.94671665, 0.8148141 ,\n",
       "        0.87191495, 0.32408665, 0.58840532, 0.79007379, 0.30404059,\n",
       "        0.58324098, 0.16948358, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segnet_model.evaluate_segmentation( inp_images_dir=\"dataset1/images_prepped_test/\"  , annotations_dir=\"dataset1/annotations_prepped_test/\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c734775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "segnet_out = segnet_model.predict_segmentation(\n",
    "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "    out_fname=\"segnet_out.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf635d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
